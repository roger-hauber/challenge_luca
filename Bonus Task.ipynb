{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84c53cd3",
   "metadata": {},
   "source": [
    "# Bonus Challenge - Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "787f58a4",
   "metadata": {},
   "source": [
    "- Scrape names and population numbers of all 97 localities (\"Ortsteile\") in Berlin\n",
    "    - From Wikipedia: https://en.wikipedia.org/wiki/Boroughs_and_neighborhoods_of_Berlin\n",
    "    <br>\n",
    "    <br>\n",
    "- Scrape zip codes and corresponding localities from another site\n",
    "    - https://www.berlinstadtservice.de/xinh/Postleitzahlen_Berlin_Alphabetisch.html\n",
    "<br>\n",
    "<br>\n",
    "- Use the business/search endpoint from the Yelp API to collect results for Berlin with search terms \"Italian\" and \"Pizza\", results include name, rating and zip code of restaurant adress\n",
    "<br>\n",
    "<br>\n",
    "- Merge all this info together, include only restaurants with rating 4 or higher and then look for the locality with the most people per (good) Italian restaurant. This region could be seen as \"underserved\" and a offer a potential opening for a new restaurant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f36a26c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a1cea65",
   "metadata": {},
   "source": [
    "## Scrape Wiki Page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f8b3ceba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the full html of the page\n",
    "wiki_resp = requests.get(\"https://en.wikipedia.org/wiki/Boroughs_and_neighborhoods_of_Berlin\")\n",
    "wiki_soup = BeautifulSoup(wiki_resp.content, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "90e46d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The <dl> tag is the table subheading for each of the 12 burroughs followed by a table of their localities\n",
    "all_dls = wiki_soup.find_all(\"dl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "005d22fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loop through all <dl> tags i.e. burroughs and collect name and population from the current <tr> (cur_row)\n",
    "# store both values as tuples and collect them in a list\n",
    "lst_of_name_pop = []\n",
    "for dl in all_dls:\n",
    "    cur_table = dl.find_next(\"tbody\").find_next(\"tr\")\n",
    "    \n",
    "    cur_row = cur_table.find_next(\"tr\")\n",
    "    \n",
    "    i = 0\n",
    "    while i <= 15:\n",
    "        pop = cur_row.find_next(\"td\").find_next(\"td\").find_next(\"td\").text\n",
    "        name = cur_row.find_next(\"a\").find_next(\"a\").text\n",
    "        \n",
    "        name_pop = (name, pop)\n",
    "        lst_of_name_pop.append(name_pop)\n",
    "        #names.append(cur_row.find_next(\"a\").find_next(\"a\").text)\n",
    "        #populations.append(cur_row.find_next(\"td\").find_next(\"td\").find_next(\"td\").text)\n",
    "        i += 1\n",
    "        cur_row = cur_row.find_next(\"tr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d3a254d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Because the tables are of different length but the while loop is calibrated for the longest one, there are duplicates\n",
    "unique_name_pop = list(set(lst_of_name_pop))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "21fb0c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Through the mismatch of lengths there are also some pairings of names and other names. \n",
    "# Get rid of them and separate the real values into lists for names and pops\n",
    "names = []\n",
    "pops = []\n",
    "\n",
    "# We try to convert the population number to float, if that fails, we discard it and if it works both values name and pop\n",
    "# are added to the lists\n",
    "for tup in unique_name_pop:\n",
    "    \n",
    "    try:\n",
    "        float(tup[1].replace(\"\\n\", \"\").replace(\",\", \"\"))\n",
    "    except:\n",
    "        continue\n",
    "    else:\n",
    "        names.append(tup[0])\n",
    "        pops.append(tup[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b864e570",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace the new line character in pops and get rid of \"Tausenderkomma\"\n",
    "pops = [float(pop.replace(\"\\n\", \"\").replace(\",\", \"\")) for pop in pops]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d47e2813",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make it a Dataframe!\n",
    "df_pops_by_locality = pd.DataFrame.from_dict({\"locality\": names, \"population\": pops})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "276ed4ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>locality</th>\n",
       "      <th>population</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lichtenrade</td>\n",
       "      <td>49451.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Weißensee</td>\n",
       "      <td>45485.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Niederschönhausen</td>\n",
       "      <td>26903.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rudow</td>\n",
       "      <td>41040.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Wartenberg</td>\n",
       "      <td>2433.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            locality  population\n",
       "0        Lichtenrade     49451.0\n",
       "1          Weißensee     45485.0\n",
       "2  Niederschönhausen     26903.0\n",
       "3              Rudow     41040.0\n",
       "4         Wartenberg      2433.0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pops_by_locality.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd215c47",
   "metadata": {},
   "source": [
    "## Scrape zip codes and localities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ccf1a558",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.berlinstadtservice.de/xinh/Postleitzahlen_Berlin_Alphabetisch.html\"\n",
    "resp_scrape = requests.get(url)\n",
    "\n",
    "soup = BeautifulSoup(resp_scrape.content, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "19be7002",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conveniently all zip code entries share a unique tag\n",
    "table_entries = soup.find_all(\"td\")\n",
    "\n",
    "zip_codes = []\n",
    "\n",
    "# loop through entries to extract the full text, containing zip codes and name in one string\n",
    "for ent in table_entries:\n",
    "    zip_codes.append(ent.text)\n",
    "\n",
    "#clean it up\n",
    "clean_zip = []\n",
    "\n",
    "for ent in zip_codes:\n",
    "    ent = ent.replace(\"B-\", \"\")\n",
    "    clean_zip.append(ent)\n",
    "\n",
    "#first part of the string split is the zip code and second part the name\n",
    "plz = []\n",
    "localities = []\n",
    "for ent in clean_zip:\n",
    "    plz.append(ent.split()[0])\n",
    "    localities.append(\" \".join(ent.split()[1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7a860604",
   "metadata": {},
   "outputs": [],
   "source": [
    "### df from localities and postcodes\n",
    "df_zip_local = pd.DataFrame.from_dict({\"locality\": localities, \"zip_code\": plz})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c532631",
   "metadata": {},
   "source": [
    "## Yelp API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "57d9b815",
   "metadata": {},
   "outputs": [],
   "source": [
    "# API key is in a non-tracked txt file, so the key is not on GitHub\n",
    "\n",
    "with open(\"key.txt\", \"r\") as file:\n",
    "    key = file.read()\n",
    "\n",
    "key = key.strip(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b74cc2f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n"
     ]
    }
   ],
   "source": [
    "# empty dict of businesses with key \"name\", \"rating\", \"zip code\"\n",
    "restaurants = {\"name\": [], \"rating\":[], \"zip_code\": []}\n",
    "\n",
    "# API calls -- 50 results per call, with offset increasing so we get new results. In total 1000 results\n",
    "offset = 0\n",
    "while offset <= 950:\n",
    "    url = f\"https://api.yelp.com/v3/businesses/search?location=berlin&term=food&categories=italian%2C%20pizza&limit=50&offset={offset}\"\n",
    "\n",
    "    headers = {\n",
    "        \"accept\": \"application/json\",\n",
    "        \"Authorization\": f\"Bearer {key}\"\n",
    "    }\n",
    "    response = requests.get(url, headers=headers)\n",
    "    print(response.status_code)\n",
    "    \n",
    "    resp_dict = response.json()\n",
    "    \n",
    "    for ent in resp_dict[\"businesses\"]:\n",
    "        restaurants[\"name\"].append(ent[\"alias\"])\n",
    "        restaurants[\"rating\"].append(ent[\"rating\"])\n",
    "        restaurants[\"zip_code\"].append(ent[\"location\"][\"zip_code\"])\n",
    "    offset += 50\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "98e04cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make dataframe of the 1000 restaurants, including name, rating and zip_code\n",
    "\n",
    "df_rest = pd.DataFrame.from_dict(restaurants)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "712fd434",
   "metadata": {},
   "source": [
    "## Bringing it all together.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3383d48c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First merge locality names to restaurants based on zip code\n",
    "df_restaurants = df_rest.merge(df_zip_local, on= \"zip_code\", how= \"inner\")\n",
    "\n",
    "#drop restaurants with rating under 4\n",
    "top_rated = df_restaurants.loc[df_restaurants.rating >= 4, ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b8c16e69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>locality</th>\n",
       "      <th>name</th>\n",
       "      <th>rating</th>\n",
       "      <th>zip_code</th>\n",
       "      <th>population</th>\n",
       "      <th>per_cap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Marzahn</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>102398.0</td>\n",
       "      <td>102398.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Hellersdorf</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>72602.0</td>\n",
       "      <td>72602.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Altglienicke</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>26101.0</td>\n",
       "      <td>26101.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Biesdorf</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>24543.0</td>\n",
       "      <td>24543.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Köpenick</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>59201.0</td>\n",
       "      <td>19733.666667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        locality  name  rating  zip_code  population        per_cap\n",
       "39       Marzahn     1       1         1    102398.0  102398.000000\n",
       "22   Hellersdorf     1       1         1     72602.0   72602.000000\n",
       "2   Altglienicke     1       1         1     26101.0   26101.000000\n",
       "4       Biesdorf     1       1         1     24543.0   24543.000000\n",
       "29      Köpenick     3       3         3     59201.0   19733.666667"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Before we merge the population info we aggregate by locality and count numbers of restaurants per locality\n",
    "agg_rest = top_rated.groupby(by=\"locality\").count().reset_index()\n",
    "\n",
    "#merge this with the population info on locality\n",
    "per_capita = agg_rest.merge(df_pops_by_locality, how=\"inner\", on = \"locality\")\n",
    "\n",
    "# calculate the amount of people per restaurant\n",
    "per_capita[\"per_cap\"] = per_capita.population/per_capita.name\n",
    "\n",
    "#sort by this new variable\n",
    "per_capita = per_capita.sort_values(by=\"per_cap\", ascending=False)\n",
    "\n",
    "#e voila -- STRONG CAVEATS..\n",
    "per_capita.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5894eeb6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3178e2c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
